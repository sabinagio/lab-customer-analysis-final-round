{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Problem (case study)\n",
    "\n",
    "##### 1.1. Data Description.\n",
    "\n",
    "> You are working as an analyst for an auto insurance company. The company has collected some data about its customers including their demographics, education, employment, policy details, vehicle information on which insurance policy is, and claim amounts. You will help the senior management with some business questions that will help them to better understand their customers, improve their services, and improve profitability.\n",
    "\n",
    "##### 1.2. Goal.\n",
    "\n",
    "The business objectives are to:\n",
    "- retain customers\n",
    "- analyze relevant customer data\n",
    "- develop focused customer retention programs\n",
    "\n",
    "Our task in this project is:\n",
    "> Based on the analysis, take targeted actions to increase profitable customer response, retention, and growth.\n",
    "\n",
    "#### 2. Getting data - read the `.csv` file.\n",
    "\n",
    "Import the libraries & modules needed throughout the project and change global settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "pd.set_option('max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read `.csv` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('files_for_lab/csv_files/marketing_customer_analysis.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Data Cleaning & Wrangling. Exploratory Data Analysis.\n",
    "\n",
    "##### 3.1. Standardize headers names.\n",
    "\n",
    "Review the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can remove the *Unnamed: 0* column as it is identical to the index column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review the rest of the columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can fix the typo, change the capitalization to lowercase, and replace all spaces with underscores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns = {'EmploymentStatus': 'Employment Status'}, inplace=True)\n",
    "df.columns = df.columns.str.lower()\n",
    "df.columns = df.columns.str.replace(\" \", \"_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2. Review and address the `NaN` values.\n",
    "\n",
    "Find and review the `NaN` values in each column as a % of the total number of rows. However, before doing so, we will remove duplicate rows (i.e. rows with the same *customer* value), as they could skew the % of `NaN` values. We'll also set the *customer* column as the index for further reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset='customer', inplace=True)\n",
    "df.set_index('customer', drop=True, inplace=True)\n",
    "\n",
    "nan_values = df.isna().sum()\n",
    "nan_values_percentage = nan_values * 100 / df.shape[0]\n",
    "print(nan_values_percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the *vehicle_type* column has 50% missing values, we can drop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('vehicle_type', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest of the columns only have ~3% `NaN` values each (This used to be 5% before duplicate rows were removed). Therefore, we can check how much data we would lose if we were to remove the rest of the `NaN` values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_df = df[(df['state'].isna()) | (df['response'].isna()) | \n",
    "                    (df['months_since_last_claim'].isna()) | (df['number_of_open_complaints'].isna()) |\n",
    "                    (df['vehicle_class'].isna()) | (df['vehicle_size'].isna())]\n",
    "\n",
    "print(nan_df.shape[0] * 100 / df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the rows with at least one `NaN` value represent ~9% of the total number of rows (this used to be 16% before dropping duplicates), we cannot remove all of them. Let's check how many rows with `NaN` values the categorical columns _state_ and _response_ have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_df1 = df[(df['state'].isna()) | (df['response'].isna())]\n",
    "print(nan_df1.shape[0] * 100 / df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the percentage is identical to the one initially calculated for each of the columns, we can conclude that wherever there is a `NaN` value in the *state* column, there is also a `NaN` value in the *response* column. Now, we will check if it's feasible to replace the `NaN` values with the mode of the columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_count = df['state'].value_counts()\n",
    "response_count = df['response'].value_counts()\n",
    "print(states_count)\n",
    "print(response_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could choose California as the default state, however Oregon is relatively close in numbers (this used to be the case before droping duplicates too). Therefore, we'll drop the rows, which will automatically remove the `NaN` values in the _response_ column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df['state'].isna() == False) | (df['response'].isna() == False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will follow the same logic for the *vehicle_class* and *vehicle_size* categorical columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_df2 = df[(df['vehicle_class'].isna()) | (df['vehicle_size'].isna())]\n",
    "print(nan_df2.shape[0] * 100 / df.shape[0])\n",
    "\n",
    "vehicle_class_count = df['vehicle_class'].value_counts()\n",
    "vehicle_size_count = df['vehicle_size'].value_counts()\n",
    "print(vehicle_class_count)\n",
    "print(vehicle_size_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we confirmed that for each `NaN` value in the *vehicle_class* column, there is a corresponding `NaN` value in the *vehicle_size* column. Secondly, in this case the modes of the columns are further apart from the second most encountered value, so we can replace the `NaN` values with the columns mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_class_mode = df['vehicle_class'].mode()[0]\n",
    "vehicle_size_mode = df['vehicle_size'].mode()[0]\n",
    "\n",
    "df['vehicle_class'] = df['vehicle_class'].fillna(vehicle_class_mode)\n",
    "df['vehicle_size'] = df['vehicle_size'].fillna(vehicle_size_mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the other two columns, we can replace the `NaN` values with the median. Before doing so, we will briefly check that the values are either integers or floats, so we can apply the median:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.dtypes)\n",
    "\n",
    "median_months = df['months_since_last_claim'].median()\n",
    "median_open_complaints = df['number_of_open_complaints'].median()\n",
    "\n",
    "df['months_since_last_claim'] = df['months_since_last_claim'].fillna(median_months)\n",
    "df['number_of_open_complaints'] = df['number_of_open_complaints'].fillna(median_open_complaints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.3. Categorical Features.\n",
    "\n",
    "We can see the categorical features by looking at what data we have in each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the categorical features are: *customer*, *state*, *response*, *coverage*, *education*, *employment_status*, *gender*, *location_code*, *marital_status*, *policy_type*, *policy*, *renew_offer_type*, *sales_channel*, *vehicle_class*, *vehicle_size*.\n",
    "\n",
    "We can split these categorical features into:\n",
    "- **nominal features:** *customer*, *state*, *response*, *employment_status*, *gender*, *location_code*, *marital_status*, *policy_type*, *sales_channel*, *vehicle_class*\n",
    "* **ordinal features:** *coverage*, *education*, *policy*, *renew_offer_type*, *vehicle_size*\n",
    "\n",
    "##### 3.4. Numerical features\n",
    "\n",
    "We can also see that the numerical features are: *customer_lifetime_value*, *effective_to_date* (which can be converted to # of years, months, days), *income*, *monthly_premium_auto*, *months_since_last_claim*, *months_since_policy_inception*, *number_of_open_complaints*, *number_of_policies*. The *total_claim_amount* is also a numerical column, but not a feature, as it is the value we want to predict.\n",
    "\n",
    "We can split the numerical features into discrete and continuous numerical data by looking at the number of unique values in each numerical column. First, however, we will check that the data is stored correctly in the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only need to convert the *effective_to_date* data to datetime format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['effective_to_date'] = pd.to_datetime(df['effective_to_date'], errors='raise')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can have a look at the number of unique values in each of the numerical columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df:\n",
    "    if df[column].dtype != np.object:\n",
    "        print(column, \":\", len(df[column].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now see which of our numerical data is:\n",
    "- **discrete:** *effective_to_date*, *monthly_premium_auto*, *months_since_last_claim*, *months_since_policy_inception*, *number_of_open_complaints*, *number_of_policies*\n",
    "* **continuous:** *customer_lifetime_value*, *income*, *total_claim_amount* \n",
    "\n",
    "** Noting that the data we counted as discrete may not be inherently discrete, but it does take only very few unique values in comparison to the rest of the dataset (which has 10279 values).\n",
    "\n",
    "##### 3.5. Data Exploration.\n",
    "\n",
    "First off, we can get a sense of the data (ranges, variance, mean) by using the *describe* method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, it might be easier to visualize all of the columns to get a sense of the data distribution:\n",
    "- bar plots for categorical data\n",
    "- distribution plots for numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df:\n",
    "    if df[column].dtype == np.object:\n",
    "        x = df[column].unique()\n",
    "        y = df[column].value_counts()\n",
    "        fig, ax = plt.subplots(figsize = (12, 9))\n",
    "        plt.title(column)\n",
    "        plt.bar(x, y)\n",
    "        plt.show()    \n",
    "    elif df[column].dtype == np.number:\n",
    "        sns.displot(df[column])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can notice that the education data is not clean, as we have one category (*College*), that can mean either *Bachelor's*, *Master's*, or *Doctoral* degree. In this case, we'll choose to reduce the number of possible options to *College* and *High School or Below* so we don't treat the *College* category as completely separate from the other 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_education(x):\n",
    "    if x in ['Doctor', 'Bachelor', 'Master']:\n",
    "        x = 'College'\n",
    "    return x\n",
    "\n",
    "df['education'] = df['education'].apply(replace_education)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also notice that:\n",
    "- most of the customers have been to college, are employed, live in suburban areas, and have responded 'No' (however we're unsure if this means they have responded 'No' to an insurance renewal or a different question)\n",
    "- there's an almost equal number of male and female customers\n",
    "- the insurances seem to be mostly corporate and typically offer basic coverage\n",
    "\n",
    "It would make sense that people living in suburban areas are more likely to use a car to commute and by extension, also purchase a car policy insurance. Similarly, it makes sense to have more corporate insurance policies if most people are employed. Now, are there any other interesting points to be uncovered from the data? For example:\n",
    "- What type of insurances do people in different states go for? Or coverage?\n",
    "- Are different vehicle sizes associated with different insurance coverages or are they equally distributed?\n",
    "- Are the renew offer types dependent on the sales channel?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x='state', hue='policy_type', data=df, kind='count')\n",
    "sns.catplot(x='state', hue='coverage', data=df, kind='count')\n",
    "sns.catplot(x='vehicle_size', hue='coverage', data=df, kind='count')\n",
    "sns.catplot(x='sales_channel', hue='renew_offer_type', data=df, kind='count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also look at the Pearson and Spearman correlations in our dataset and remove any colinear data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num = df.select_dtypes(np.number)\n",
    "\n",
    "corr = df_num.corr()\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "sns.heatmap(corr, annot=True, mask=mask)\n",
    "plt.show()\n",
    "\n",
    "corr = df_num.corr('spearman')\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "sns.heatmap(corr, annot=True, mask=mask)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's no obvious strong correlation between the numerical features, so we will perform Chi-squared test for our categorical variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat = df.select_dtypes(np.object)\n",
    "\n",
    "def chi_squared_test(df_cat):\n",
    "    corr_chi = pd.DataFrame([], columns=df_cat.columns, index=df_cat.columns)\n",
    "    for column_1 in df_cat:\n",
    "        for column_2 in df_cat:\n",
    "            st_resp = pd.crosstab(df_cat[column_1], df_cat[column_2])\n",
    "            chi2, p, dof, array = chi2_contingency(st_resp)\n",
    "            corr_chi.loc[column_1, column_2] = round(p, 3)\n",
    "\n",
    "    for column in corr_chi:\n",
    "        corr_chi[column] = pd.to_numeric(corr_chi[column], errors='raise')\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "    mask = np.triu(np.ones_like(corr_chi, dtype=bool))\n",
    "    sns.heatmap(corr_chi, annot=True, mask=mask)\n",
    "    plt.show()\n",
    "\n",
    "chi_squared_test(df_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will remove *policy_type* and *vehicle_size* as they are clearly dependednt on *policy* and *vehicle_class*, respectively and have less detailed information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['policy_type', 'vehicle_size'], axis=1, inplace=True)\n",
    "df_cat = df.select_dtypes(np.object)\n",
    "chi_squared_test(df_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We did not remove any more columns as that greatly affected the linear regression score when tested."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Processing Data\n",
    "\n",
    "##### 4.1. Spotting and addressing outliers.\n",
    "\n",
    "We will look at the outliers in the continuous numerical data using boxplots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous = ['customer_lifetime_value', 'income', 'total_claim_amount']\n",
    "\n",
    "for i in range(0, len(continuous)):\n",
    "    plt.figure(i)\n",
    "    sns.boxplot(x=df[continuous[i]], data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the *customer_lifetime_value* and *total_claim_amount* have plenty of outliers, so we will clean these columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(columns, df, threshold=1.5):\n",
    "    for column in columns:\n",
    "        upper = np.percentile(df[column],75)\n",
    "        lower = np.percentile(df[column],25)\n",
    "        iqr = upper - lower\n",
    "        upper_limit = upper + threshold * iqr\n",
    "        lower_limit = lower - threshold * iqr\n",
    "        df = df[(df[column]>lower_limit) & (df[column]<upper_limit)]\n",
    "    return df\n",
    "\n",
    "remove_outliers(continuous, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2. Normalization. \n",
    "\n",
    "Before applying the linear regression, we want to make sure that our data is normalized so as to not skew the model. Additionally, we will apply the Box-Cox method to slightly improve the R2 score, given that typically the distribution of errors is approximated to a normal distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df):\n",
    "    y = df['total_claim_amount']\n",
    "    y = y.apply(pd.to_numeric, errors='ignore')\n",
    "    X = df.drop('total_claim_amount', axis=1)\n",
    "    X_num = X.select_dtypes(include=np.number)\n",
    "    X_cat = X.select_dtypes(include='object')\n",
    "    return X, y, X_num, X_cat\n",
    "\n",
    "def normalize_data(X_num):\n",
    "    transformer = MinMaxScaler().fit(X_num) \n",
    "    x_minmax = transformer.transform(X_num)\n",
    "    X_num_norm = pd.DataFrame(x_minmax, columns=X_num.columns)\n",
    "    return X_num_norm\n",
    "\n",
    "def Box_Cox(X_num_norm):\n",
    "    for column in X_num_norm:\n",
    "        if len(X_num_norm[column].unique()) > 500:\n",
    "            X_num_norm[column] = np.where(X_num_norm[column]<=0, np.nan, X_num_norm[column])        \n",
    "            X_num_norm[column] = X_num_norm[column].fillna(X_num_norm[column].mean())\n",
    "            X_num_norm[column], _ = stats.boxcox(X_num_norm[column])\n",
    "    return X_num_norm\n",
    "\n",
    "\n",
    "df_dummy = df.copy()\n",
    "X, y, X_num, X_cat = split_data(df_dummy)\n",
    "X_num_norm = normalize_data(X_num)\n",
    "X_num_norm = Box_Cox(X_num_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.3. Encoding Categorical Data.\n",
    "\n",
    "We will use One-Hot Encoding to encode the categorical data, as ordinal encoding yielded worse results in the linear regression model (as per lab 7]):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_data(X_cat):\n",
    "    encoder = OneHotEncoder(handle_unknown='error', drop='first')\n",
    "    encoder.fit(X_cat)\n",
    "    encoded = encoder.transform(X_cat).toarray()\n",
    "    cat_encoded = pd.DataFrame(encoded)\n",
    "    cat_encoded.columns = encoder.get_feature_names_out()\n",
    "    return cat_encoded\n",
    "\n",
    "cat_encoded = encode_data(X_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.4. Splitting into train set and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([X_num_norm, cat_encoded], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Run Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "predictions  = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = r2_score(y_test, predictions)\n",
    "RMSE = mean_squared_error(y_test, predictions, squared=False)\n",
    "MSE = mean_squared_error(y_test, predictions)\n",
    "MAE = np.mean(abs(y_test.to_numpy() - predictions))\n",
    "\n",
    "print(\"r2 = \", r2)\n",
    "print(\"RMSE = \", RMSE)\n",
    "print(\"MSE = \", MSE)\n",
    "print(\"MAE = \", MAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Reporting - present results.\n",
    "\n",
    "The R2 score for the model means that ~77.95% of the variation in the *total_claim_amount* can be explained by variations in the rest of the variables. Whilst this is not a bad result, it could benefit from some improvement, either by:\n",
    "- gathering more data \n",
    "* changing the model used to fit the data\n",
    "- exploring other variables that might influence the dataset\n",
    "\n",
    "By looking at the coefficients, we can see which variables have the most weight in the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = pd.DataFrame(data=model.coef_, index=X.columns)\n",
    "print(coefficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the *monthly_premium_auto* has the largest weight in our model and it's positively correlated with the *total_claim_amount*, suggesting that customers with a higher premium also claim more overall. Most of the other features have a less than 10x smaller weight in the model, suggesting they're not as indicative of the *total_claim_amount*, even when compounded (e.g. in the case of categorical columns, which were one-hot encoded). This might be explained by the fact that higher monthly premium autos also involve the possibility to claim more in the case of an accident. Therefore, the results do not point to an obvious course of action for the business, other than gathering more data or potentially using industry data. "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
